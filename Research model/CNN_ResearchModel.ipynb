{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"dataset.csv\"  # Update this path to your CSV file location\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Shuffle the dataset\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Separate features and labels\n",
    "labels = df['class']\n",
    "features = df.drop(columns=['frame_name', 'class'])\n",
    "\n",
    "# Ensure all features are numeric\n",
    "features = features.apply(pd.to_numeric, errors='coerce')\n",
    "features = features.fillna(0)\n",
    "\n",
    "# Convert the DataFrame to a NumPy array\n",
    "features_array = features.to_numpy(dtype=np.float32)  # Ensure the array is of type float32\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# One-hot encode the labels\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(features_array, labels_categorical, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define a function to create the model\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(80, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 6 # Number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "test_accuracies = []\n",
    "test_losses = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_full):\n",
    "    X_train, X_val = X_train_full[train_index], X_train_full[val_index]\n",
    "    y_train, y_val = y_train_full[train_index], y_train_full[val_index]\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_model((features_array.shape[1],), labels_categorical.shape[1])\n",
    "    history = model.fit(X_train, y_train, epochs=70, batch_size=5, validation_data=(X_val, y_val), callbacks=[early_stopping], shuffle=True)\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Evaluate the model on test set (using the same test set for simplicity)\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "# Calculate mean and standard deviation for validation and test metrics\n",
    "mean_val_loss = np.mean(val_losses)\n",
    "std_val_loss = np.std(val_losses)\n",
    "mean_val_acc = np.mean(val_accuracies)\n",
    "std_val_acc = np.std(val_accuracies)\n",
    "\n",
    "mean_test_loss = np.mean(test_losses)\n",
    "std_test_loss = np.std(test_losses)\n",
    "mean_test_acc = np.mean(test_accuracies)\n",
    "std_test_acc = np.std(test_accuracies)\n",
    "\n",
    "# Print final validation and test metrics\n",
    "print(f\"Validation Loss: {mean_val_loss:.4f} ± {std_val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {mean_val_acc:.4f} ± {std_val_acc:.4f}\")\n",
    "print(f\"Test Loss: {mean_test_loss:.4f} ± {std_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {mean_test_acc:.4f} ± {std_test_acc:.4f}\")\n",
    "\n",
    "# Save the last trained model\n",
    "model.save(\"model.h5\")\n",
    "\n",
    "# Plot training and validation accuracy for the last fold\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Plot training and validation loss for the last fold\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Check class distribution in the test set\n",
    "test_class_distribution = np.argmax(y_test, axis=1)\n",
    "print(\"Test set class distribution:\", np.bincount(test_class_distribution))\n",
    "\n",
    "# Check class distribution in the predictions\n",
    "predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "print(\"Predicted class distribution:\", np.bincount(predictions))\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_class_distribution, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
